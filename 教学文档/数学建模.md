## 1. 规划问题



### 1.1. 线性规划

**格式：**
$$
\begin{aligned}
& \min c^{T} x \\
\text { s.t. } &\left\{\begin{array}{l}
A x \leq b \\
A e q \cdot x=b e q \\
l b \leq x \leq u b
\end{array}\right.
\end{aligned}
$$

**例子：**
$$
\begin{aligned}
&\max z=2 x_{1}+3 x_{2}-5 x_{3} \\
&\text { s.t. }\left\{\begin{array}{l}
x_{1}+x_{2}+x_{3}=7 \\
2 x_{1}-5 x_{2}+x_{3} \geq 10 \\
x_{1}+3 x_{2}+x_{3} \leq 12 \\
x_{1}, x_{2}, x_{3} \geq 0
\end{array}\right.
\end{aligned}
$$

**代码：**

```python
# 导入包
from scipy import optimize
import numpy as np

# 确定c,A,b,Aeq,beq
c = np.array([2, 3, -5])
A = np.array([[-2, 5, -1], [1, 3, 1]])
b = np.array([-10, 12])
Aeq = np.array([[1, 1, 1]])
beq = np.array([7])

# 求解
res = optimize.linprog(-c, A, b, Aeq, beq)
print(res)
```

**运行结果：**

```python
     con: array([1.80713222e-09])
     fun: -14.57142856564506
 message: 'Optimization terminated successfully.'
     nit: 5
   slack: array([-2.24583019e-10,  3.85714286e+00])
  status: 0
 success: True
       x: array([6.42857143e+00, 5.71428571e-01, 2.35900788e-10])
```

































### 1.2整数规划

**格式：**
$$
\begin{aligned}
& \min c^{T} x \\
\text { s.t. } &\left\{\begin{array}{l}
A x \leq b \\
A e q \cdot x=b e q \\
l b \leq x \leq u b
\end{array}\right.
\end{aligned}
$$

**例子：**
$$
\begin{aligned}
&\max z=3 x_{1}+x_{2}+3 x_{3} \\
&\left\{\begin{array}{l}
-x_{1}+2 x_{2}+x_{3} \leq 4 \\
4 x_{2}-3 x_{3} \leq 2 \\
x_{1}-3 x_{2}+2 x_{3} \leq 3 \\
x_{1}, x_{2}, x_{3} \geq 0 \\
x_{1}, x_{2}, x_{3} \text { 均为整数 }
\end{array}\right.
\end{aligned}
$$

**==重要提示：运行代码前一定要 切换环境！！！ 切换环境！！！ 切换环境！！！==**

**代码：**

```python
# 导入包
import numpy as np
import cvxpy as cp

# 设置目标函数中变量个数
n = 3

# 输入目标函数的系数
c = np.array([3, 1, 3])

# 输入约束条件的系数矩阵（3×3）
a = np.array([[-1, 2, 1], [0, 4, -3], [1, -3, 2]])

# 输入b值（3×1）
b = np.array([4, 2, 3])

# 创建x，个数是3
x = cp.Variable(n, integer=True)

# 明确目标函数（此时c是3×1，x是3×1,但python里面可以相乘）
objective = cp.Maximize(cp.sum(c * x))

# 明确约束条件，其中a是3×3，x是3×1,a*x=b(b为3×1的矩阵)
constriants = [0 <= x, a * x <= b]
# 求解问题
prob = cp.Problem(objective, constriants)
# 这里solver必须使用cp.CPLEX,否则计算不出来
resluts = prob.solve(solver=cp.CPLEX)

# 输入结果
print(prob.value)  # 目标函数的值
print(x.value)  # 各x的值
```

**运行结果：**

```python
23.0
[5. 2. 2.]
```

































### 1.3 非线形规划



scipy.optimize 模块中提供了多个用于非线性规划问题的方法，适用于不同类型的问题

- **brent()**　　单变量无约束优化问题，混合使用牛顿法/二分法。
- **fmin()**　　多变量无约束优化问题，使用单纯性法，只需要利用函数值，不需要函数的导数或二阶导数。
- **leatsq() **　　非线性最小二乘问题，用于求解非线性最小二乘拟合问题。
- **minimize() **　　约束优化问题，使用拉格朗日乘子法将约束优化转化为无约束优化问题。



#### 1.3.1 scipy.optimize.brent() 求解单变量无约束优化问题

非线性规划最简单的形式是一维搜索，一维搜索的常用方法是函数逼近法和区间收缩法。

brent() 函数是 scipy.optimize 模块中求解单变量无约束优化问题最小值的首选方法。这是牛顿法和二分法的混合方法，既能保证稳定性又能快速收敛。

**格式：**

```python
scipy.optimize.brent(func, args=(), brack=None, tol=1.48e-08, full_output=0, maxiter=500)
```

**optimize.brent() 的主要参数：**

- **func: callable f(x,\*args)** 　目标函数 f(x)，以函数形式表示，可以通过 *args 传递参数
- **args: tuple**　　可选项，以 f(x,*args) 的形式将可变参数 p 传递给目标函数 𝑓(𝑥,𝑝)f(x,p) 
- **brack: tuple**　　可选项，搜索算法的开始区间（不是指 x 的上下限）
- **tol: float**　　可选项，可以接受的误差范围
- **full_output: bool**　　可选项，如果是True（或者1）则返回参数: xmin, fval, iter, funcalls
- **maxiter, int**　　可选项，解决方案的最大迭代次数

**optimize.brent() 的主要返回值：**

- **xmin: ndaray ** 　　返回函数达到最小值时的 x（注意是局部最优，不一定是全局最优）
- **fval: float** 　　返回函数的最优值（默认不返回，仅当 full_output 为 1 时返回）
- **iter: int**　　返回迭代次数
- **funcalls: int**　　函数的评估次数

**代码：**

```python
from scipy.optimize import brent
import numpy as np

# 1. Demo1：单变量无约束优化问题(Scipy.optimize.brent)
def objf(x):  # 目标函数
    fx = x**2 - 8*np.sin(2*x+np.pi)
    return fx

xIni = -5.0
xOpt= brent(objf, brack=(xIni,2))
print("xIni={:.4f}\tfxIni={:.4f}".format(xIni,objf(xIni))
print("xOpt={:.4f}\tfxOpt={:.4f}".format(xOpt,objf(xOpt)))
```

**运行结果：**

```python
xIni=-5.0000    fxIni=29.3522
xOpt=-0.7391    fxOpt=-7.4195
```

























#### 1.3.2 scipy.optimize.fmin() 求解多变量无约束优化问题

多变量无约束优化问题的算法很多，分类方式也很多。从使用者的角度来说可以分为：只使用目标函数值、使用导数（梯度下降法）、使用二阶导数。大体来说，使用导数的算法收敛较快，使用二阶导数收敛更快，但是收敛快也容易陷入局部最优。

fmin() 函数是 SciPy.optimize 模块中求解多变量无约束优化问题（最小值）的首选方法，采用下山单纯性方法。下山单纯性方法又称 Nelder-Mead 法，只使用目标函数值，不需要导数或二阶导数值，是最重要的多维无约束优化问题数值方法之一。

**格式：**

```python
scipy.optimize.fmin(func, x0, args=(), xtol=0.0001, ftol=0.0001, maxiter=None, maxfun=None, full_output=0, disp=1, retall=0, callback=None, initial_simplex=None)
```

**optimize.fmin() 的主要参数：**

- **func: callable f(x,\*args)** 　目标函数 f(x)，以函数形式表示，可以通过 *args 传递参数
- **x0: nadarray**　　搜索算法的初值
- **args: tuple**　　可选项，以 f(x,*args) 的形式将可变参数 p 传递给目标函数 f(x,p) 
- **xtol: float**　　可选项，可以接受的迭代中产生的误差 (针对x)
- **ftol: number**　　可选项，可以接受的迭代中产生的误差 (针对y)
- **maxiter: int**　　可选项，最大的迭代次数
- **maxfun: number**　　可选项，要评估的函数的最大个数
- **full_output: bool**　　可选项，如果为True (或者1)，则输出fopt 和 warnflag
- **disp: bool**　　可选项，如果为True (或者1)，则输出收敛相关数据
- **retall: bool**　　可选项，如果为True (或者1)，则输出每次迭代后返回的列表
- **callback: callable**　　可选项，在每次迭代后调用，作为 callback(xk)，其中 xk 是当前参数向量
- **initial_simplex: rray_like of shape (N + 1, N)**　　可选项，

**optimize.fmin() 的主要返回值：**

- **xopt: ndarray**　　返回最小值时的 x 值。
- **fopt: float**　　返回最小值时的目标函数值，fopt=func(xopt)。
- **iter: int**　　执行的迭代次数
- **funcalls: int**　　进行的函数调用次数
- **warnflag: int**　　1. 进行的最大功能评估次数　　2. 达到最大迭代次数
- **allvecs: list**　　每次迭代的解决方案

**代码：**

```python
from scipy.optimize import brent, fmin, minimize
import numpy as np

# 2. Demo2：多变量无约束优化问题(Scipy.optimize.brent)
# Rosenbrock 测试函数
def objf2(x):  # Rosenbrock benchmark function
    fx = sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1 - x[:-1]) ** 2.0)
    return fx

xIni = np.array([-2, -2])
xOpt = fmin(objf2, xIni)
print("xIni={:.4f},{:.4f}\tfxIni={:.4f}".format(xIni[0],xIni[1],objf2(xIni)))
print("xOpt={:.4f},{:.4f}\tfxOpt={:.4f}".format(xOpt[0],xOpt[1],objf2(xOpt)))
```

**运行结果：**

```python
Optimization terminated successfully.
         Current function value: 0.000000
         Iterations: 79
         Function evaluations: 149
xIni=-2.0000,-2.0000    fxIni=3609.0000
xOpt=1.0000,1.0000    fxOpt=0.0000
```

























#### 1.3.3 scipy.optimize.minimize() 求解非线性规划问题

minimize() 函数是 SciPy.optimize 模块中求解多变量优化问题的通用方法，可以调用多种算法，支持约束优化和无约束优化。

**格式：**

```python
scipy.optimize.minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None, callback=None, options=None)
```

**optimize.minimize() 的主要参数：**

- **fun: callable f(x,\*args)**　　目标函数 f(x)，以函数形式表示，可以通过 *args 传递参数。
- **x0: nadarray**　　shape(n,) 搜索算法的初值，n 是决策变量个数。
- **args: tuple**　　可选项，将可变参数传递给目标函数 fun、导数函数 jac 和二阶导数函数 hess。
- **method: str**　　可选项，选择优化算法。默认算法为 BFGS, L-BFGS-B, SLSQP（取决于问题有没有边界条件和约束条件）
- **jac:**　　可选项，梯度计算方法。可以以函数形式表示，或选择 '2-point', '3-point', 'cs'。该选项只能用于 CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov, trust-exact 和 trust-constr 算法。
- **hess:**　　可选项，Hessian 矩阵计算方法。可以以函数形式表示，或选择 '2-point', '3-point', 'cs'。该选项只能用于 Newton-CG, dogleg, trust-ncg, trust-krylov, trust-exact 和 trust-constr 算法。
- **bounds:**　　可选项，变量的边界条件（上下限，lb<=x<=ub）。该选项只能用于 Nelder-Mead, L-BFGS-B, TNC, SLSQP, Powell 和 trust-constr 算法。
- **constraints:**　　可选项，定义约束条件 f(x)>=0。该选项只能用于 COBYLA, SLSQP 和 trust-constr 算法，注意不同算法中对于约束条件的定义是不同的。

**optimize.minimize() 的主要返回值：**

- **res: ** 　　返回优化结果，以对象方式表示，主要包括优化是否成功、决策变量的优化值 xOpt。

**optimize.minimize() 的优化算法选项：**

optimize.minimize() 的默认算法为 BFGS, L-BFGS-B, SLSQP（取决于问题有没有边界条件和约束条件），可以通过 "method=None" 选项调用多种算法：

**无约束问题优化算法**

- **method=‘CG’ **：　　非线性共轭梯度算法，只能处理无约束优化问题，需要使用一阶导数函数。
- **method=‘BFGS’ **：　　BFGS 拟牛顿法，只能处理无约束优化问题，需要使用一阶导数函数。BFGS 算法性能良好，是无约束优化问题的默认算法。
- **method=‘Newton-CG’ **：　　截断牛顿法，只能处理无约束优化问题，需要使用一阶导数函数，适合处理大规模问题。
- **method=‘dogleg’ **：　　dog-leg 信赖域算法，需要使用梯度和 Hessian（必须正定），只能处理无约束优化问题，
- **method=‘trust-ncg’ **：　　采用牛顿共轭梯度信赖域算法，需要使用梯度和 Hessian（必须正定），只能处理无约束优化问题，适合大规模问题。
- **method=‘trust-exact’**：　　求解无约束极小化问题的信赖域方法，需要梯度和Hessian（不需要正定）。
- **method=‘trust-krylov’**：　　使用Newton-GLTR 信赖域算法度，需要使用梯度和 Hessian（必须正定），只能处理无约束优化问题，适合中大规模问题。

**边界约束条件问题优化算法**

- **method=‘Nelder-Mead’**：　　下山单纯性法，可以处理边界约束条件（决策变量的上下限），只使用目标函数，不使用导数函数、二阶导数，鲁棒性强。
- **method=‘L-BFGS-B’ **：　　改进的 BFGS 拟牛顿法，L- 指有限内存，-B 指边界约束，可以处理边界约束条件，需要使用一阶导数函数。L-BFGS_B 算法性能良好，消耗内存量很小，适合处理大规模问题，是边界约束优化问题的默认算法。
- **method=‘Powell’**：　　改进的共轭方向法，可以处理边界约束条件（决策变量的上下限）。
- **method=‘TNC’ **：　　截断牛顿法，可以处理边界约束条件

**带有约束条件问题优化算法**

- **method=‘COBYLA’ **：　　线性近似约束优化方法，通过对目标函数和约束条件的线性逼近处理非线性问题。只使用目标函数，不需要导数或二阶导数值，可以处理约束条件。
- **method=‘SLSQP’ **：　　序贯最小二乘规划算法，可以处理边界约束、等式约束和不等式约束条件。SLSQP 算法性能良好，是带有约束条件优化问题的默认算法。
- **method=‘trust-constr’ **：　　信赖域算法，通用的约束最优化方法，适合处理大规模问题。

**==详见：==**https://scipy.github.io/devdocs/reference/generated/scipy.optimize.minimize.html?highlight=scipy%20optimize%20minimize#scipy.optimize.minimize

**编程步骤说明：**

1. 导入 scipy、numpy 包；
2. 定义目标函数 objf3(x)，输入变量 x 表示向量，返回值 fx 是目标函数的计算结果 。
3. 定义边界约束，即优化变量的上下限：
   - minimize() 默认无边界约束条件，即各自变量的取值范围没有限制；
   - 如果设置边界约束，要对每个自变量（决策变量）定义其上下限，注意定义边界约束的格式；
   - 如果某个自变量没有上限（下限），则表示为 None 。
4. 定义 x 的初值。
5. 求解最小化问题 resRosen，其中目标函数 objf3 和搜索的初值点 xIni 是必需的，指定优化方法和边界条件是可选项。如果优化问题是求最大值 maxFx，可以通过 minFx = - maxFx 的变换来实现。
6. 通过调用最小化问题的返回值 resRosen.x 得到最优点 xOpt。

**代码：**

```python
from scipy.optimize import minimize
import numpy as np


# 3. Demo3：多变量边界约束优化问题(Scipy.optimize.minimize)
# 定义目标函数
def objf3(x):  # Rosenbrock 测试函数
    fx = sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1 - x[:-1]) ** 2.0)
    return fx


# 定义边界约束（优化变量的上下限）
b0 = (0.0, None)  # 0.0 <= x[0] <= Inf
b1 = (0.0, 10.0)  # 0.0 <= x[1] <= 10.0
b2 = (-5.0, 100.)  # -5.0 <= x[2] <= 100.0
bnds = (b0, b1, b2)  # 边界约束

# 优化计算
xIni = np.array([1., 2., 3.])
resRosen = minimize(objf3, xIni, method='SLSQP', bounds=bnds)
xOpt = resRosen.x

print("xOpt = {:.4f}, {:.4f}, {:.4f}".format(xOpt[0], xOpt[1], xOpt[2]))
print("min f(x) = {:.4f}".format(objf3(xOpt)))
```

**运行结果：**

```python
xOpt = 1.0000, 1.0000, 1.0000
min f(x) = 0.0000
```

























#### 1.3.4 约束非线性规划问题实例



##### 1.3.4.1 数学说明



**例子：**
$$
\begin{aligned}
&\min f(x)=a x_{1}^{2}+b x_{2}^{2}+c x_{3}^{2}+d \\
&\text { s.t. }\left\{\begin{array}{l}
x_{1}^{2}-x_{2}+x_{3}^{2} \geq 0 \\
x_{1}+x_{2}^{2}+x_{3}^{3} \leq 20 \\
-x_{1}-x_{2}^{2}+2=0 \\
x_{2}+2 x_{3}^{2}=3 \\
x_{1}, x_{2}, x_{3} \geq 0
\end{array}\right.
\end{aligned}
$$


**转化后函数：**
$$
\begin{aligned}
&\min f(x)=a x_{1}^{2}+b x_{2}^{2}+c x_{3}^{2}+d \\
&\text { s.t. }\left\{\begin{array}{l}
x_{1}^{2}-x_{2}+x_{3}^{2} \geq 0 \\
-\left(x_{1}+x_{2}^{2}+x_{3}^{3}-20\right) \geq 0 \\
-x_{1}-x_{2}^{2}+2=0 \\
x_{2}+2 x_{3}^{2}-3=0 \\
x_{1}, x_{2}, x_{3} \geq 0
\end{array}\right.
\end{aligned}
$$

















##### 1.3.4.2 Python 例程 1：

**程序说明：**

1. 在本例程中，目标函数中的参数 a, b, c, d 在子程序中直接赋值，这种实现方式最简单；
2. 定义边界约束，即优化变量的上下限，与 3.2 中的例程相同，用 minimize() 函数中的选项 bounds=bnds 进行定义。
3. 定义约束条件：
   - 本案例有 4个约束条件，2个等式约束、2个不等式约束，上节中已写成标准形式；
   - 本例程将每个约束条件作为一个子函数定义，
   - minimize() 函数对约束条件按照字典格式： {'type': 'ineq', 'fun': functionname} 进行定义。'type' 的键值可选 'eq' 和 'ineq'，分别表示的是约束和不等式约束；functionname是定义约束条件的函数名。
4. 求解最小化问题 res，其中目标函数 objF4 和搜索的初值点 x0 是必需的，指定优化方法和边界条件、约束条件是可选项。
5. 通过调用最小化问题的返回值可以得到优化是否成功的说明（res.message）、自变量的优化值（res.x）和目标函数的优化值（res.fun）。

**代码：**

```python
from scipy.optimize import minimize
import numpy as np


# 4. Demo4：约束非线性规划问题(Scipy.optimize.minimize)
def objF4(x):  # 定义目标函数
    a, b, c, d = 1, 2, 3, 8
    fx = a * x[0] ** 2 + b * x[1] ** 2 + c * x[2] ** 2 + d
    return fx


# 定义约束条件函数
def constraint1(x):  # 不等式约束 f(x)>=0
    return x[0] ** 2 - x[1] + x[2] ** 2


def constraint2(x):  # 不等式约束 转换为标准形式
    return -(x[0] + x[1] ** 2 + x[2] ** 3 - 20)


def constraint3(x):  # 等式约束
    return -x[0] - x[1] ** 2 + 2


def constraint4(x):  # 等式约束
    return x[1] + 2 * x[2] ** 2 - 3


# 定义边界约束
b = (0.0, None)
bnds = (b, b, b)

# 定义约束条件
con1 = {'type': 'ineq', 'fun': constraint1}
con2 = {'type': 'ineq', 'fun': constraint2}
con3 = {'type': 'eq', 'fun': constraint3}
con4 = {'type': 'eq', 'fun': constraint4}
cons = ([con1, con2, con3, con4])  # 3个约束条件

# 求解优化问题
x0 = np.array([1., 2., 3.])  # 定义搜索的初值
res = minimize(objF4, x0, method='SLSQP', bounds=bnds, constraints=cons)

print("Optimization problem (res):\t{}".format(res.message))  # 优化是否成功
print("xOpt = {}".format(res.x))  # 自变量的优化值
print("min f(x) = {:.4f}".format(res.fun))  # 目标函数的优化值
```

**运行结果：**

```python
Optimization problem (res):    Optimization terminated successfully
xOpt = [0.6743061  1.15138781 0.96140839]
min f(x) = 13.8790
```

















##### 1.3.4.3 Python 例程 2：

**程序说明：**

1. 本例程的问题与 4.2 中的例程 1 是相同的，结果也相同，但编程实现的方法进行了改进；
2. 本例程中目标函数中的参数 a, b, c, d 在主程序中赋值，通过 args 把参数传递到子程序，这种实现方式使参数赋值更为灵活，特别是适用于可变参数的问题；注意目标函数的定义不是 def objF5(x,args)，而是 def objF5(args)，要特别注意目标函数的定义和实现方法。
3. 定义约束条件：
   - 本案例有 4 个约束条件，2个等式约束、2个不等式约束，上节中已写成标准形式；
   - 本例程将 4 个约束条件放在一个子函数中定义，是程序更加简洁。
   - 注意每个约束条件仍然按照字典格式 {'type': 'ineq', 'fun': functionname} 进行定义，但 functionname 并不是函数名，而是一个 lambda 匿名函数。
4. 通过调用最小化问题的返回值可以得到优化是否成功的说明（res.message）、自变量的优化值（res.x）和目标函数的优化值（res.fun）。

**代码：**

```python
from scipy.optimize import minimize
import numpy as np


# 5. Demo5：约束非线性规划问题(Scipy.optimize.minimize)
def objF5(args):  # 定义目标函数
    a, b, c, d = args
    fx = lambda x: a * x[0] ** 2 + b * x[1] ** 2 + c * x[2] ** 2 + d
    return fx


def constraint1():  # 定义约束条件函数
    cons = ({'type': 'ineq', 'fun': lambda x: (x[0] ** 2 - x[1] + x[2] ** 2)},  # 不等式约束 f(x)>=0
            {'type': 'ineq', 'fun': lambda x: -(x[0] + x[1] ** 2 + x[2] ** 3 - 20)},  # 不等式约束 转换为标准形式
            {'type': 'eq', 'fun': lambda x: (-x[0] - x[1] ** 2 + 2)},  # 等式约束
            {'type': 'eq', 'fun': lambda x: (x[1] + 2 * x[2] ** 2 - 3)})  # 等式约束
    return cons


# 定义边界约束
b = (0.0, None)
bnds = (b, b, b)
# 定义约束条件
cons = constraint1()
args1 = (1, 2, 3, 8)  # 定义目标函数中的参数
# 求解优化问题
x0 = np.array([1., 2., 3.])  # 定义搜索的初值
res1 = minimize(objF5(args1), x0, method='SLSQP', bounds=bnds, constraints=cons)

print("Optimization problem (res1):\t{}".format(res1.message))  # 优化是否成功
print("xOpt = {}".format(res1.x))  # 自变量的优化值
print("min f(x) = {:.4f}".format(res1.fun))  # 目标函数的优化值
```

**运行结果：**

```python
Optimization problem (res1):    Optimization terminated successfully
xOpt = [0.6743061  1.15138781 0.96140839]
min f(x) = 13.8790
```

















##### 1.3.4.4 Python 例程 3：

**程序说明：**

1. 本例程的问题与 4.3 中的例程 2 是相同的，结果也相同，但编程实现的方法进行了改进；
2. 本例程中约束条件中的参数在主程序中赋值，通过 args 把参数传递到约束条件定义的子程序，这种实现方式使参数赋值更为灵活，特别是适用于可变参数的问题。
3. 本例程中将边界约束条件即自变量的取值范围作为不等式约束条件处理，不另作边界条件设置。
4. 通过调用最小化问题的返回值可以得到优化是否成功的说明（res.message）、自变量的优化值（res.x）和目标函数的优化值（res.fun）。

**代码：**

```python
from scipy.optimize import minimize
import numpy as np


# 6. Demo6：约束非线性规划问题(Scipy.optimize.minimize)
def objF6(args):  # 定义目标函数
    a, b, c, d = args
    fx = lambda x: a * x[0] ** 2 + b * x[1] ** 2 + c * x[2] ** 2 + d
    return fx


def constraint2(args):
    xmin0, xmin1, xmin2 = args
    cons = ({'type': 'ineq', 'fun': lambda x: (x[0] ** 2 - x[1] + x[2] ** 2)},  # 不等式约束 f(x)>=0
            {'type': 'ineq', 'fun': lambda x: -(x[0] + x[1] ** 2 + x[2] ** 3 - 20)},  # 不等式约束 转换为标准形式
            {'type': 'eq', 'fun': lambda x: (-x[0] - x[1] ** 2 + 2)},  # 等式约束
            {'type': 'eq', 'fun': lambda x: (x[1] + 2 * x[2] ** 2 - 3)},  # 等式约束
            {'type': 'ineq', 'fun': lambda x: (x[0] - xmin0)},  # x0 >= xmin0
            {'type': 'ineq', 'fun': lambda x: (x[1] - xmin1)},  # x1 >= xmin1
            {'type': 'ineq', 'fun': lambda x: (x[2] - xmin2)})  # x2 >= xmin2
    return cons


# 求解优化问题
args1 = (1, 2, 3, 8)  # 定义目标函数中的参数
args2 = (0.0, 0.0, 0.0)  # xmin0, xmin1, xmin2
cons2 = constraint2(args2)

x0 = np.array([1., 2., 3.])  # 定义搜索的初值
res2 = minimize(objF6(args1), x0, method='SLSQP', constraints=cons2)

print("Optimization problem (res2):\t{}".format(res2.message))  # 优化是否成功
print("xOpt = {}".format(res2.x))  # 自变量的优化值
print("min f(x) = {:.4f}".format(res2.fun))  # 目标函数的优化值
```

**运行结果：**

```python
Optimization problem (res2):    Optimization terminated successfully
xOpt = [0.6743061  1.15138781 0.96140839]
min f(x) = 13.8790
```









































## 2. 数据分析相关算法



### 2.1. 层次分析法



**代码：**

```python
import numpy as np

# 输入比较矩阵
array = np.array([[1, 2, 7, 5, 5],
                  [1 / 2, 1, 4, 3, 3],
                  [1 / 7, 1 / 4, 1, 1 / 2, 1 / 3],
                  [1 / 5, 1 / 3, 2, 1, 1],
                  [1 / 5, 1 / 3, 3, 1, 1]])

# 定义一个max_cr用来判断一致性是否可以接受
max_cr = 0.1

# 一致性指标RI表(层次分析法很少有大于10个指标，如果超过10则建立二级指标体系)
n_ri = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
                 [0, 0, 0.52, 0.89, 1.12, 1.26, 1.36, 1.41, 1.46, 1.49, 1.52, 1.54, 1.56, 1.58, 1.59]])

# 给出对象数目
n = array.shape[0]
# 给出矩阵的特征值(eigenvalue)和特征向量(eigenvector)
eigenvalue, eigenvector = np.linalg.eig(array)
# 给出矩阵最大特征值
max_eigenvalue = max(list(map(abs, eigenvalue)))
# 计算CR
cr = ((max_eigenvalue - n) / (n - 1)) / n_ri[1][n-1]

# 判断一致性是否通过
if cr > max_cr:
    # 一致性未通过
    print("一致性未通过！请修改判断矩阵！")
else:
    # 一致性通过，给出权重
    # 给出绝对值最大的特征值对应的特征向量
    max_eigenvector = eigenvector[:, list(map(abs, eigenvalue)).index(max_eigenvalue)]
    # 标准化特征向量即为权重
    standard_max_eigenvector = list(map(abs, max_eigenvector)) / sum(list(map(abs, max_eigenvector)))
    print(standard_max_eigenvector)
```

































### 2.2. Topsis优劣解距离法



























3.

